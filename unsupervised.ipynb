{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71b002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"data_cleaned.csv\")\n",
    "\n",
    "# Feature selection\n",
    "cluster_features = [\n",
    "    \"acousticness\", \"danceability\", \"duration_ms\", \"energy\",\n",
    "    \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\",\n",
    "    \"tempo\", \"valence\"\n",
    "]\n",
    "cluster_features = [c for c in cluster_features if c in df.columns]\n",
    "data = df.dropna(subset=cluster_features).copy()\n",
    "\n",
    "print(\"Total samples:\", len(data))\n",
    "print(\"Features:\", cluster_features)\n",
    "\n",
    "# Sample for faster k search\n",
    "max_sample = 20000\n",
    "data_sample = data.sample(min(max_sample, len(data)), random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_sample_scaled = scaler.fit_transform(data_sample[cluster_features])\n",
    "\n",
    "# Smaller subset for silhouette\n",
    "sil_max = 5000\n",
    "idx_sil = np.random.choice(\n",
    "    X_sample_scaled.shape[0],\n",
    "    size=min(sil_max, X_sample_scaled.shape[0]),\n",
    "    replace=False\n",
    ")\n",
    "X_sil = X_sample_scaled[idx_sil]\n",
    "\n",
    "# Try k values\n",
    "k_values = range(2, 11)\n",
    "inertias = []\n",
    "sil_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels_sample = kmeans.fit_predict(X_sample_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    labels_sil = kmeans.predict(X_sil)\n",
    "    sil_scores.append(silhouette_score(X_sil, labels_sil))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(k_values, inertias, marker=\"o\")\n",
    "plt.title(\"Elbow\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(k_values, sil_scores, marker=\"o\")\n",
    "plt.title(\"Silhouette\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_k = k_values[int(np.argmax(sil_scores))]\n",
    "print(\"Best k:\", best_k)\n",
    "\n",
    "# Final model\n",
    "X_full_scaled = scaler.transform(data[cluster_features])\n",
    "kmeans_final = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans_final.fit_predict(X_full_scaled)\n",
    "data[\"cluster\"] = cluster_labels\n",
    "\n",
    "# Quick silhouette and DB index\n",
    "full_sil_max = 5000\n",
    "idx_full = np.random.choice(\n",
    "    X_full_scaled.shape[0],\n",
    "    size=min(full_sil_max, X_full_scaled.shape[0]),\n",
    "    replace=False\n",
    ")\n",
    "sil_final = silhouette_score(X_full_scaled[idx_full], cluster_labels[idx_full])\n",
    "db_final = davies_bouldin_score(X_full_scaled, cluster_labels)\n",
    "\n",
    "print(\"Silhouette:\", sil_final)\n",
    "print(\"Davies Bouldin:\", db_final)\n",
    "\n",
    "print(data[\"cluster\"].value_counts().sort_index())\n",
    "\n",
    "# Cluster profile\n",
    "cluster_profile = data.groupby(\"cluster\")[cluster_features].mean()\n",
    "print(cluster_profile)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cluster_profile, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Popularity per cluster\n",
    "if \"popularity\" in data.columns:\n",
    "    pop_by_cluster = data.groupby(\"cluster\")[\"popularity\"].mean()\n",
    "    print(pop_by_cluster)\n",
    "    pop_by_cluster.plot(kind=\"bar\")\n",
    "    plt.title(\"Popularity by cluster\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Genre distribution\n",
    "if \"main_genre\" in data.columns:\n",
    "    for c in sorted(data[\"cluster\"].unique()):\n",
    "        print(f\"\\nCluster {c}:\")\n",
    "        print(data[data[\"cluster\"] == c][\"main_genre\"].value_counts().head(10))\n",
    "\n",
    "# PCA plot\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_full_scaled)\n",
    "data[\"pca1\"] = X_pca[:, 0]\n",
    "data[\"pca2\"] = X_pca[:, 1]\n",
    "\n",
    "plot_sample = data.sample(min(8000, len(data)), random_state=42)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=plot_sample,\n",
    "    x=\"pca1\", y=\"pca2\",\n",
    "    hue=\"cluster\", palette=\"tab10\", alpha=0.5\n",
    ")\n",
    "plt.title(\"PCA clusters\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Quick ranking helper\n",
    "print(\"\\nCluster rankings:\")\n",
    "key_feats = [\"danceability\", \"energy\", \"acousticness\", \"instrumentalness\", \"valence\", \"tempo\"]\n",
    "key_feats = [c for c in key_feats if c in cluster_profile.columns]\n",
    "\n",
    "for feat in key_feats:\n",
    "    print(f\"\\n{feat}:\")\n",
    "    print(cluster_profile[feat].sort_values(ascending=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
